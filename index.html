<!DOCTYPE html>
<html>

<head>

    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />
    <title> Final Project - CS180 </title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">

    <script src="http://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script> <!-- stats.js lib -->
    <script src="http://threejs.org/examples/js/libs/stats.min.js"></script>

    <link rel="stylesheet" type="text/css" href="style.css" />

    <script src="script.js"></script>
    <script src="particles.js"></script>

</head>

<body>

    <!-- <div class="particles particleContainer">
        <div id="particles-js">
            <a
                role="button"
                href="#projects"
                data-aos="fade-up"
                data-aos-duration="1500"
                class="projectTitleContainer btn btn-outline-light"
            >
                <p class="projectTitle display-2 fw-normal">Projects</p>
            </a>
        </div>
    </div> -->

    <div class="main-container" style="position: relative;">
        <div id="particles-js" style="height: 100%; min-height: 100vh;"></div>

        <div class="main-description mt-3" style="display:inline-block">

            <h1 class="display-1 text-center"> Siddharth Nath </h1>
            <p class="lead text-center fs-4"> Computer Science & Data Science @ UC Berkeley </p>
            <div class="d-flex justify-content-evenly links">
                <a href="https://github.com/SidNath21" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="#0d6efd" class="bi bi-github"
                        viewBox="0 0 16 16">
                        <path
                            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                    </svg>
                </a>
                <a href="mailto:sidnath21@gmail.com" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="#0d6efd" class="bi bi-envelope"
                        viewBox="0 0 16 16">
                        <path
                            d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1H2zm13 2.383l-4.758 2.855L15 11.114v-5.73zm-.034 6.878L9.271 8.82 8 9.583 6.728 8.82l-5.694 3.44A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.739zM1 11.114l4.758-2.876L1 5.383v5.73z" />
                    </svg>
                </a>
                <a href="https://www.linkedin.com/in/siddharth-nath/" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="#0d6efd" class="bi bi-linkedin"
                        viewBox="0 0 16 16">
                        <path
                            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
                    </svg>
                </a>
            </div>
            <p class="text-center fs-5">  </p>
            <div class="mx-auto">
                <div class="d-grid gap-2 d-md-flex justify-content-md-center">
                    <button class="btn btn-lg btn-outline-primary me-md-2" type="button"
                        onClick="document.getElementById('image-quilting').scrollIntoView();""> Projects </button>
                    <button class=" btn btn-lg btn-outline-primary" type="button"
                        onClick="document.getElementById('neural-style-transfer').scrollIntoView();"> About Me </button>
                </div>

            </div>


            <div class="downArrow bounce">
                <img width="40" height="40" alt="" src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiA/PjwhRE9DVFlQRSBzdmcgIFBVQkxJQyAnLS8vVzNDLy9EVEQgU1ZHIDEuMS8vRU4nICAnaHR0cDovL3d3dy53My5vcmcvR3JhcGhpY3MvU1ZHLzEuMS9EVEQvc3ZnMTEuZHRkJz48c3ZnIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDMyIDMyIiBoZWlnaHQ9IjMycHgiIGlkPSLQodC70L7QuV8xIiB2ZXJzaW9uPSIxLjEiIHZpZXdCb3g9IjAgMCAzMiAzMiIgd2lkdGg9IjMycHgiIHhtbDpzcGFjZT0icHJlc2VydmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiPjxwYXRoIGQ9Ik0yNC4yODUsMTEuMjg0TDE2LDE5LjU3MWwtOC4yODUtOC4yODhjLTAuMzk1LTAuMzk1LTEuMDM0LTAuMzk1LTEuNDI5LDAgIGMtMC4zOTQsMC4zOTUtMC4zOTQsMS4wMzUsMCwxLjQzbDguOTk5LDkuMDAybDAsMGwwLDBjMC4zOTQsMC4zOTUsMS4wMzQsMC4zOTUsMS40MjgsMGw4Ljk5OS05LjAwMiAgYzAuMzk0LTAuMzk1LDAuMzk0LTEuMDM2LDAtMS40MzFDMjUuMzE5LDEwLjg4OSwyNC42NzksMTAuODg5LDI0LjI4NSwxMS4yODR6IiBmaWxsPSIjMTIxMzEzIiBpZD0iRXhwYW5kX01vcmUiLz48Zy8+PGcvPjxnLz48Zy8+PGcvPjxnLz48L3N2Zz4=" />
            </div>

        </div>

    </div>







    <div class="project-body mx-auto" style="width: 80%;">

        <div class="project-overview" id="image-quilting">
            <h1 class="display-5"> Image Quilting Overview </h1>
            <p class="lead">
                In this assignment I learned about the different methods I can use for texture synthesis and texture
                transfer.
                Texture synthesis descibes generating a larger texture image from a smaller sample while texture
                transfer is the process of giving an object the appearance of having a specific texture while
                maintaining the object's basic shape.
                This project follows the implementation of the paper <a
                    href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/efros-siggraph01.pdf">
                    <i>Image Quilting for Texture Synthesis and Transfer</i> </a> which required me to familiarize
                myself with the paper and implement the methods descibed.
                The three methods I implemented for texture synthesis are:
            </p>
            <ol>
                <li> Randomly Sampled Texture </li>
                <li> Overlapping Patches </li>
                <li> Seam Finding </li>
            </ol>
            <p class="lead">
                For the texture transfer, I used the Seam Finding method as it performed better than the other two.
            </p>
        </div>

        <div class="1_1">
            <h1 class="display-6"> Part 1.1: Texture synthesis - Randomly Sampled Texture </h1>
            <p>

                The most naive way to do texture synthesis is by randomly sampling square patches from the smaller
                sample texture in order to create the output image of a given size.
                For this I implemented the function <code>quilt_random(sample, out_size, patch_size)</code> that creates
                an output image of size <code>out_size</code> by tiling square patches of size <code>patch_size</code>
                from the <code>sample</code> texture.
                <br> <br>
                Here are the results of this method:
            </p>

            <h5> Results </h5>
            <p> Below I listed the input textures and larger output textures </p>

            <div class="container grid-container">

                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/samples/bricks_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Brick Sample </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/samples/text_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Text Sample </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/samples/white_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> White Sample </p>
                            </div>
                        </div>
                    </div>



                </div>
            </div>


            <div class="container grid-container">

                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/naive_bricks_small.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_random(sample, 300, 30)</code> </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/naive_text_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_random(sample, 300, 30)</code> </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/naive_white_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_random(sample, 300, 30)</code> </p>
                            </div>
                        </div>
                    </div>

                </div>
            </div>

        </div>


        <div class="1_2">
            <h1 class="display-6"> Part 1.2: Texture synthesis - Overlapping Patches </h1>
            <p>
                A better approach for texture synthesis is to have the sampled patches overlap with the existing ones
                along the edges of the patches.
                After sampling a random patch to be the top-left corner, I sample new patches that overlap with the
                existing ones by choosing the patch that has the minimum cost over the overlapping region.
                For this I implemented the function
                <code>quilt_simple(sample, out_size, patch_size, overlap, tol)</code> that samples new patches of size
                <code>patch_size</code> that overlap with the existing patches by <code>overlap</code> pixels.
                By computing the SSD cost across the overlapping region for every possible patch of size
                <code>patch_size</code> from the input image, I select a random patch with low cost out of the
                <code>tol</code> lowest-cost patches.
                <br> <br>

            </p>

            <h5> Results </h5>
            <p> Below I listed the input textures and larger output textures </p>

            <div class="container grid-container">

                <div class="row align-items-center justify-content-center">

                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/simple_bricks_small.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_simple(sample, 300, 45, 9, 3)</code> </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/simple_text_small.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_simple(sample, 300, 45, 9, 3)</code> </p>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/simple_white_small.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> <code>quilt_simple(sample, 300, 45, 9, 3)</code> </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>


            <p>
                Here we can see that the results are much better than the naive approach! The synthesized textures look
                more coherent and overall they have less artifacts than the ones generated by the naive approach.
            </p>

            <div class="1_1">
                <h1 class="display-6"> Part 1.3: Texture synthesis - Seam Finding </h1>
                <p class="">
                    This method is an extension of the overlapping patches method but instead of naively overlapping the
                    new sampled patch on top of the existing patches, this method finds the minimum SSD cost of a
                    contiguous path from the left to right side of the patch.
                    For this, I implemented the function
                    <code>quilt_cut(sample, out_size, patch_size, overlap, tol)</code> Samples square patches of size
                    <code>patch_size</code> from <code>sample</code> using seam finding on the overlapping regions in
                    order to create an output image of size <code>out_size</code>.
                </p>

                <h5> Results </h5>
                <p> Below I listed the input textures and larger output textures </p>

                <hr>

                <div class="container grid-container">

                    <div class="row align-items-center justify-content-center">
                        <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/better_bricks_small.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> <code>quilt_cut(sample, 300, 45, 9, 5)</code> </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/better_text_small.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> <code>quilt_cut(sample, 300, 45, 9, 5)</code> </p>
                                </div>
                            </div>
                        </div>

                        <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/better_white_small.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> <code>quilt_cut(sample, 300, 45, 9, 5)</code> </p>
                                </div>
                            </div>
                        </div>


                    </div>
                </div>

                <p>
                    Although the improvements are less noticeable, the resulting textures are more visually pleasing as
                    they contain less artifacts! The improvement is most noticeable with the white texture as the edges
                    are not as distinct and noticable as the previous overlapping patches method. Additionally, the text
                    is better aligned and more legible than before.
                </p>


            </div>

            <div class="1_1">
                <h1 class="display-6"> Part 2: Texture Transfer </h1>
                <p class="lead">
                    The next part of this project involved using the seam finding texture synthesis method to create a
                    texture sample that is guided by a pair of sample/target correspondence images.
                    The end result is an output image of the same shape/structure as the target image in the style of
                    the sample texture image.
                    The paper mentions that we need to define a "correspondence map" to compute the difference between
                    the texture image and the target image. For this project, I opted to use the blurred gray-scale
                    versions of the target and texture to compare the two images.
                    For this I implemented a function
                    <code>texture_transfer(sample, patch_size, overlap, tol, guidance_im, alpha)</code> that follows the
                    same logic as the seam finding function. The main difference is that now I have to use
                    <code>guidance_im</code> to determine the shape of the output while using <code>sample</code> to
                    determine the style/texture of the output image. To account for this change, I modified the cost
                    function that is used to search for next patch to sample. The new cost function is now:
                    $$ \alpha * [\text{SSD of Overlapping Region}] + (1 - \alpha) * [\text{difference of texture
                    (sample) patch & the target (guidance_im) patch} ] $$
                    By carefully weighting the <code>alpha</code> parameter along with <code>patch_size</code>, I got
                    the following results:
                </p>

                <hr>
                <h5> Results </h5>
                <p> Below I listed the sample textures, the corresponding target image, and the final output image </p>

                <div class="container grid-container">

                    <div class="row align-items-center justify-content-center">
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/sketch.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Source Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_texture.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/feynman.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Target Image </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_target.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Source </p>
                                </div>
                            </div>
                        </div>

                    </div>
                </div>



                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/sketch_feynman_transfer.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text">
                                    <code>texture_transfer(sample, 27, 4, 1, guidance_image, 0.5)</code> </p>
                            </div>
                        </div>
                    </div>
                </div>


                <hr>


                <div class="container grid-container">

                    <div class="row align-items-center justify-content-center">
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/rocks.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Source Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_texture_2.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/sid_small.jpeg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Target Image </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_target_2.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Source </p>
                                </div>
                            </div>
                        </div>

                    </div>
                </div>



                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/rocks_sid_small_transfer.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text">
                                    <code>texture_transfer(sample, 17, 5, 1, guidance_image, 0.5)</code> </p>
                            </div>
                        </div>
                    </div>
                </div>


                <hr>

                <div class="container grid-container">

                    <div class="row align-items-center justify-content-center">
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/white_small.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Source Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_texture_3.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Texture </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/samples/avocado.jpeg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Target Image </p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/blur_target_3.jpg" class="card-img-top" alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text"> Correspondence Map - Source </p>
                                </div>
                            </div>
                        </div>

                    </div>


                    <div class="row align-items-center justify-content-center">
                        <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                            <div class="card">
                                <img src="./imageQuilting/results/white_small_avocado_transfer.jpg" class="card-img-top"
                                    alt="Image 1">
                                <div class="card-body text-center">
                                    <p class="card-text">
                                        <code>texture_transfer(sample, 15, 4, 1, guidance_image, 0.7)</code> </p>
                                </div>
                            </div>
                        </div>
                    </div>


                </div>

            </div>

            <div class="project-insight">
                <h1 class="display-6"> Bells & Whistles: Texture Transfer + Blending </h1>
                <p class="lead">
                    To get more satisfying results, I decided to use a combination of texture transfer and blending to
                    create a face-in-toast image.
                    To accomplish this I utilized the Laplacian pyramid blending methods that I implemented in Project
                    2.
                </p>

                <p>
                    I started by first cropping the white edges from the border of the orignal toast image so the white
                    borders wouldn't be sampled during the texture transfer.
                    Using the cropped toast image as the source texture and Vishali as the target image, I ran the
                    <code>texture_transfer</code> method and got the following output:
                </p>

                <hr>


                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/samples/toast.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Sample Toast </p>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/samples/vishali_face_2.jpeg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Target Face </p>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/toast_vishali_face_2_transfer.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text">
                                    <code>texture_transfer(cropped_sample, 27, 4, 1, guidance_image, 0.5)</code> </p>
                            </div>
                        </div>
                    </div>
                </div>


                Given this output, we can define a binary mask on the original toast image and use that for our
                Laplacian blending between the original toast and the result of the texture transfer method:
                <br> <br>
                <h5>Results:</h5>

                <div class="row align-items-center justify-content-center">
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/mask.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Original Binary Mask </p>
                            </div>
                        </div>
                    </div>
                    <!-- <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/mask.jpg" class="card-img-top"
                                alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Target Face </p>
                            </div>
                        </div>
                    </div> -->
                    <div class="col-lg-4 col-md-6 col-sm-12 mb-4">
                        <div class="card">
                            <img src="./imageQuilting/results/face-in-toast.jpg" class="card-img-top" alt="Image 1">
                            <div class="card-body text-center">
                                <p class="card-text"> Face-In-Toast! </p>
                            </div>
                        </div>
                    </div>
                </div>

            </div>


            <div class="project-insight">
                <h1 class="display-6"> Image Quilting Insights </h1>
                <p class="lead">
                    I really enjoyed completing this project and learning more about how I can implement image quilting
                    from scratch. My favorite part was reading through the paper and seeing the results of the texture
                    transfer on my own images.
                </p>
            </div>
        </div>

        <hr>

        <div class="project-overview" id="neural-style-transfer">
            <h1 class="display-5"> Neural Algorithm of Artistic Style Overview </h1>
            <p class="lead">
                This project involved reimplementing the paper <a href="https://arxiv.org/pdf/1508.06576.pdf"> <i>A
                        Neural Algorithm of Artistic Style</i> </a>!
                The paper explains how to use Convolutional Neural Networks - specifically the VGG-19 architecture - to
                capture the content and style of a given image.
                The key finding of this paper is that representations of content and style in the CNN are separable;
                therefore, we can manipulate both representations independently to perform style transfering.
            </p>

        </div>

        <div class="1_1">
            <h1 class="display-6"> Part 1: Modifying VGG-19 Architecture</h1>
            <p class="lead">
                The first step in this project involved downloading the pretrained VGG-19 CNN model to use for this
                task. The paper uses the feature space provided by the 16 convolutional and 5 pooling layers of the 19
                layer VGG-Network.
                However, the authors do no use any of the fully connect layers and they opt to replace the max-pooling
                operations with average pooling to improve performance.
                <hr>
                <br>

            <div class="mx-auto w-75">
                <img src="./neuralStyleTransfer/images/vgg_network2.png" class="img-fluid" alt="Responsive image">
            </div>
            <br>

            <p>
                The pretrained VGG-Network contains two different <code>Sequential</code> PyTorch implementations:
                features (containing the convolution and pooling layers), and classifier (containing fully connected
                layers). Since we we need the output of the individual convolution layers to measure the content and
                style loss, we use the features module!

                To extract the content and style representations from the CNN, the authors recommends using the feature
                output of convolutional layer 4_2 to learn the "content" of the image, while using output of layers 1_1,
                2_1, 3_1, 4_1, and 5_1 to learn the "style" of the image.
                Since I only need the outputs from these 6 convolutional layers, I modified the <code>forward()</code>
                function of my VGG model to return only those responses.
            </p>

            <p>
                The initial and modified network architecture after renaming layers and changing the max-pooling
                operations to avg-pooling is shown below:
            </p>

            <div class="row align-items-center justify-content-center">
                <div class="col-lg-6 col-md-6 col-sm-12 mb-4">
                    <div class="card">
                        <img src="./neuralStyleTransfer/images/initial_model.png" class="card-img-top" alt="Image 1">
                        <div class="card-body text-center">
                            <p class="card-text"> Pretrained Architecture </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-6 col-md-6 col-sm-12 mb-4">
                    <div class="card">
                        <img src="./neuralStyleTransfer/images/modified_model.png" class="card-img-top" alt="Image 1">
                        <div class="card-body text-center">
                            <p class="card-text"> Modified VGG-19 Architecture </p>
                        </div>
                    </div>
                </div>
            </div>

            </p>
        </div>

        <div class="1_1">
            <h1 class="display-6"> Part 2: Defining Loss Functions </h1>
            <p class="lead">
                Since the paper separates the content and style representations of images, we have two loss functions
                that we use when training the modified VGG-19 network.
                In other words, the loss function that we aim to minimize contains two terms: one for content and
                another for style!
            </p>
        </div>

        <hr>
        <p>

        </p>
        <h5> Content Loss </h5>

        <p>
            The authors of the paper realized that using the feature representation at convolution layer 4_2 was the
            most effective in representing the content of the image.
            However, this is a parameter that can be tuned to get different results since higher layers in the network
            capture the high-level content of an image while lower layers reproduce exact pixel values of the original
            image.
        </p>

        <p>
            To calculate the content loss of the content image with respect to the image we are generating, we use the
            outputs of convolutional layer 4_2 in the equation below:
        </p>


        <div class="mx-auto">
            <img src="./neuralStyleTransfer/images/content_loss.jpg" alt="Responsive image">
        </div>


        <p>
            Here, the content loss is simply the Mean Squared Error (MSE) between \( F \) (the 4_2 feature map of the
            generated image) - and \( P \) (the 4_2 feature map of the content image)
        </p>

        <h5> Style Loss </h5>

        <p>
            Calculating the style loss is not as simple as the content loss. To capture the "style" of an image, we
            first build a style representation from the feature maps that calculated the correlations between the
            different feature responses. This is done by calculating the Gram Matrix - the inner product between the
            vectorized feature maps.
        </p>

        <div class="mx-auto">
            <img src="./neuralStyleTransfer/images/gram_matrix.jpg" alt="Responsive image">
        </div>

        <p>
            After computing the Gram matricies for each vectorized feature map, we cstart by minimizing the mean-squared
            distance between the entries of the Gram matrix from the original image and the Gram matrix of the image to
            be generated. For a given layer l, the contribution of that layer to the style loss is defined as:
        </p>

        <div class="w-75">
            <img src="./neuralStyleTransfer/images/style_error.jpg" class="img-fluid" alt="Responsive image">
        </div>

        <p>
            By aggregating this error across all the convolutional layers, we get the total style loss which is equal
            to:
        </p>

        <div class="w-75">
            <img src="./neuralStyleTransfer/images/style_loss.jpg" class="img-fluid" alt="Responsive image">
        </div>

        <p>
            In the equation above, \( w_{l} \) represents the weight of the contribution of each layer to the total
            loss. For this implementation, I set \( w_{l} = 1/5 \) for convolutional layers 1_1, 2_1, 3_1, 4_1, and 5_1.
            For any other layers, \( w_{l} = 0\)
        </p>

        <h5> Total Loss </h5>
        <p>
            Combining the Style Loss with the Content Loss, the total loss we minimize is:
            $$
            \LARGE{
            L_{total} (\vec{p}^{\,}, \vec{a}^{\,}, \vec{x}^{\,}) = \alpha * L_{content}(\vec{p}^{\,}, \vec{x}^{\,}) +
            \beta * L_{style}(\vec{a}^{\,}, \vec{x}^{\,})
            }
            $$
        </p>
        <p>
            Here, \(\alpha\) and \(\beta\) are parameters that control the weighting factors for content (\( \alpha \))
            and style (\( \beta \)).
        </p>

        <div class="1_1">
            <h1 class="display-6"> Part 3: Training & Results </h1>
            <p class="">
                To train this model and optimize the loss function, it is important to performing some preprocessing
                steps to get the best results.
            </p>
            <p>
                Firstly, we need to resize the images to the appropriate size; since I have access to Google Colab's GPU
                compute power, I resized the content and style images to 512 by 512 pixels.
                Additionally, we have to convert this resized image of shape (height, width, channel size) into (batch
                size, channel size, height, width) so that our images are compatible with the VGG-19 architecture!
                When downloading the pretrained model, it is also important to set the network to evaluation mode using
                <code>.eval()</code> since some of the model's layers have different behavior during training vs
                evaluation.
            </p>
        </div>

        <hr>
        <h5> Training </h5>

        <p>
            For training, I decided to use the Adam optimizer initialized with a learning rate of 0.004 - the paper did
            not specify what optimizer to use but using the Adam optimizer turned out fine.
            The paper also mentions that the ratio \(\alpha / \beta \) was either \( 1 * 10^{-3} \text{ or } 1 *
            10^{-4}\). Therefore, I started off by setting \( \alpha = 1 \) and \( \beta = 1000 \).
            In the paper, the authors initialize a randomized white-noise image to be the image that is getting
            optimized. However, I got better results by initializing the image-to-be-generated with a copy of the
            content image.
        </p>

        <p>
            After only 300 training iterations (optimizer steps), I got the following results:
        </p>

        <h5> Results </h5>

        <div class="row align-items-center justify-content-center">

            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/content/dancing.jpeg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Content </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/style/picasso.jpeg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Style </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-6 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/results/dancing_picasso.jpg" class="card-img-top"
                        alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Output </p>
                    </div>
                </div>
            </div>
        </div>

        <p>
            Content Image of a Balerina in the style of <i>Femme nue assise</i> by Pablo Picasso! The content image was
            taken from <a href="https://pytorch.org/tutorials/advanced/neural_style_tutorial.html">this</a> PyTorch
            resource. The results turned out pretty good but we lose many of the high frequency details of the
            ballerina. I tried fine-tuning different parameters such as the number of style layers and the \(\alpha
            \text{ and } \beta \) values but it did not make much improvement!
        </p>

        <hr>

        <div class="row align-items-center justify-content-center">

            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/content/berkeley.jpeg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Content </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/style/starry_night.jpg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Style </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-6 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/results/berkeley_starry_night.jpg" class="card-img-top"
                        alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Output </p>
                    </div>
                </div>
            </div>
        </div>


        <p>
            This result blends a photo of Berkeley that I took with the style of <i>The Starry Night</i> by Vincent van
            Gogh!
        </p>



        <hr>

        <div class="row align-items-center justify-content-center">

            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/content/dc.jpeg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Content </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/style/scream.jpg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Style </p>
                    </div>
                </div>
            </div>
            <div class="col-lg-6 col-md-6 col-sm-12 mb-4">
                <div class="card">
                    <img src="./neuralStyleTransfer/images/results/dc_scream.jpg" class="card-img-top" alt="Image 1">
                    <div class="card-body text-center">
                        <p class="card-text"> Output </p>
                    </div>
                </div>
            </div>
        </div>

        <p>
            This final result combines a photo that I took of Vishali with the style of <i>Der Schrei</i> by Edvard
            Munch. Similar to the first example, many smaller details of the face & body are lost as a result of this
            style transfer. In my notebook, I tried varying some of the parameters and I even set the \( \alpha:\beta \)
            ratio to \(1 * 10^{-2}\) but it didn't make a big difference!
        </p>


        <div class="project-insight">
            <h1 class="display-6"> Neural Style Transfer Insights </h1>
            <p class="lead">
                I enjoyed learning how to re-implement the paper <a href="https://arxiv.org/pdf/1508.06576.pdf"> <i>A
                        Neural Algorithm of Artistic Style</i> </a> from scratch! It was a very valuable experience
                having to dissect the paper and take in all of the information provided by the authors. Implementing
                this project was also fun since I had the chance to use some of my own images!
            </p>
        </div>

    </div>

</body>

</html>